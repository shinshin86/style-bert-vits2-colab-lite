{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@markdown # このノートブックについて\n",
        "\n",
        "#@markdown このノートブックは[litagin02/Style-Bert-VITS2リポジトリにあるGoogle Colabノートブック](https://colab.research.google.com/github/litagin02/Style-Bert-VITS2/blob/master/colab.ipynb)をベースに、Google Driveに接続する機能を除き、声の学習を行なうためだけに簡略化させたノートブックとなります。\n",
        "\n",
        "#@markdown プログラムが分かる方・より使いこなしていきたい方はベースとさせてもらった [litagin02/Style-Bert-VITS2](https://github.com/litagin02/Style-Bert-VITS2) をご覧ください。\n"
      ],
      "metadata": {
        "id": "0HqIznKny2uM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZob5Q6uJcDy"
      },
      "outputs": [],
      "source": [
        "#@markdown ## Style-Bert-VITS2のセットアップ\n",
        "#@markdown この処理を実施したら\n",
        "\n",
        "#@markdown /content/dataset/Style-Bert-VITS2/inputs\n",
        "\n",
        "#@markdown に、学習させたい音声ファイルを入れてください\n",
        "\n",
        "!git clone https://github.com/litagin02/Style-Bert-VITS2.git\n",
        "%cd Style-Bert-VITS2/\n",
        "!pip install -r requirements-colab.txt --timeout 120\n",
        "!python initialize.py --skip_default_models\n",
        "\n",
        "# 学習に必要なファイルや途中経過が保存されるディレクトリ\n",
        "dataset_root = \"/content/dataset/Style-Bert-VITS2/Data\"\n",
        "\n",
        "# 学習結果（音声合成に必要なファイルたち）が保存されるディレクトリ\n",
        "assets_root = \"/content/dataset/Style-Bert-VITS2/model_assets\"\n",
        "\n",
        "# 元となる音声ファイル（wav形式）を入れるディレクトリ\n",
        "input_dir = \"/content/dataset/Style-Bert-VITS2/inputs\"\n",
        "\n",
        "!mkdir -p {dataset_root}\n",
        "!mkdir -p {assets_root}\n",
        "!mkdir -p {input_dir}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "with open(\"configs/paths.yml\", \"w\", encoding=\"utf-8\") as f:\n",
        "    yaml.dump({\"dataset_root\": dataset_root, \"assets_root\": assets_root}, f)\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown # 作成するモデル関連の内容を入力\n",
        "#@markdown ※デフォルトのままでも問題ありません\n",
        "# モデル名（話者名）を入力\n",
        "model_name = \"your_model_name\" #@param {type:\"string\"}\n",
        "\n",
        "# こういうふうに書き起こして欲しいという例文（句読点の入れ方・笑い方や固有名詞等）\n",
        "initial_prompt = \"こんにちは。元気、ですかー？ふふっ、私は……ちゃんと元気だよ！\" #@param {type:\"string\"}\n",
        "\n",
        "!python slice.py -i {input_dir} --model_name {model_name}\n",
        "!python transcribe.py --model_name {model_name} --initial_prompt {initial_prompt} --use_hf_whisper\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## JP-Extraを有効化する\n",
        "#@markdown JP-Extra （日本語特化版）を有効化すると、日本語の能力が向上する代わりに英語と中国語は使えなくなります。\n",
        "use_jp_extra = True #@param {type: \"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## 学習のバッチサイズ。\n",
        "#@markdown VRAMのはみ出具合に応じて調整してください。\n",
        "batch_size = 4 #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## 学習のエポック数\n",
        "# 100で多すぎるほどかもしれませんが、もっと多くやると質が上がる可能性もあります\n",
        "epochs = 100 #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## 保存頻度\n",
        "#@markdown 保存頻度。何ステップごとにモデルを保存するか。分からなければデフォルトのままで。\n",
        "save_every_steps = 1000 #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown 音声ファイルの音量を正規化するかどうか\n",
        "normalize = False #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown 音声ファイルの開始・終了にある無音区間を削除するかどうか\n",
        "trim = False #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown 読みのエラーが出た場合にどうするか。\n",
        "\n",
        "#@markdown ・\"raise\"ならテキスト前処理が終わったら中断\n",
        "\n",
        "#@markdown ・\"skip\"なら読めない行は学習に使わない\n",
        "\n",
        "#@markdown ・\"use\"なら無理やり使う\n",
        "yomi_error = \"skip\" #@param {type:\"string\"}\n",
        "\n",
        "# 以降は学習に関する処理\n",
        "from gradio_tabs.train import preprocess_all\n",
        "from style_bert_vits2.nlp.japanese import pyopenjtalk_worker\n",
        "import yaml\n",
        "from gradio_tabs.train import get_path\n",
        "\n",
        "pyopenjtalk_worker.initialize_worker()\n",
        "\n",
        "preprocess_all(\n",
        "    model_name=model_name,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    save_every_steps=save_every_steps,\n",
        "    num_processes=2,\n",
        "    normalize=normalize,\n",
        "    trim=trim,\n",
        "    freeze_EN_bert=False,\n",
        "    freeze_JP_bert=False,\n",
        "    freeze_ZH_bert=False,\n",
        "    freeze_style=False,\n",
        "    freeze_decoder=False,\n",
        "    use_jp_extra=use_jp_extra,\n",
        "    val_per_lang=0,\n",
        "    log_interval=200,\n",
        "    yomi_error=yomi_error,\n",
        ")\n",
        "\n",
        "paths = get_path(model_name)\n",
        "dataset_path = str(paths.dataset_path)\n",
        "config_path = str(paths.config_path)\n",
        "\n",
        "with open(\"default_config.yml\", \"r\", encoding=\"utf-8\") as f:\n",
        "    yml_data = yaml.safe_load(f)\n",
        "yml_data[\"model_name\"] = model_name\n",
        "with open(\"config.yml\", \"w\", encoding=\"utf-8\") as f:\n",
        "    yaml.dump(yml_data, f, allow_unicode=True)\n",
        "\n",
        "if use_jp_extra:\n",
        "  # 学習 （日本語特化版を「使う」場合）\n",
        "  !python train_ms_jp_extra.py --config {config_path} --model {dataset_path} --assets_root {assets_root}\n",
        "else:\n",
        "  # 学習 （日本語特化版を「使わない」場合）\n",
        "  !python train_ms.py --config {config_path} --model {dataset_path} --assets_root {assets_root}"
      ],
      "metadata": {
        "id": "LLaLXulXKDh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Web UI起動\n",
        "#@markdown Web UIを起動して学習させたモデルを試す事ができますが、Colabからだと音声の生成ができないかも？\n",
        "!python app.py --share"
      ],
      "metadata": {
        "id": "YyJ96jr6N8vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # ONNX変換\n",
        "#@markdown 学習済みのモデルをONMXに変換します。\n",
        "\n",
        "#@markdown 変換後は\n",
        "\n",
        "#@markdown /content/dataset/Style-Bert-VITS2/model_assets/{設定したモデル名}/{設定したモデル名}_e100_s300.onnx\n",
        "\n",
        "#@markdown にモデルが出力されます\n",
        "!git fetch -p\n",
        "!git checkout -b dev origin/dev\n",
        "!pip install -r requirements-colab.txt\n",
        "!python convert_onnx.py --model /content/dataset/Style-Bert-VITS2/model_assets/your_model_name"
      ],
      "metadata": {
        "id": "iDTSPluoRb7Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}